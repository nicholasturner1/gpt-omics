{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4be436-6351-4110-b9d6-22e2ef49f68f",
   "metadata": {},
   "source": [
    "# Determining how to extract QK and OV matrices from GPT-Neo attention heads\n",
    "We'd like to analyze the composition terms for attention heads across GPT-Neo models, but we need to understand how to extract these terms out of the model in order to do that. This notebook demonstrates how to reproduce the self-attention mechanism using the extracted matrices. We'll work with the first layer for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ed681-c1b3-41f0-8c40-dd5f6aa1d820",
   "metadata": {},
   "source": [
    "## Importing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6a08f9-2a4f-48be-8f0a-db62f9c88a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nt/miniconda3/envs/gpt-neo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Automatically rounding outputs to 4 digits\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279401dc-9fe3-42ce-b2bb-c891ea4bb0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/gpt-neo-125M\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a7f037-a829-4fea-98b0-b3e46ee739ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoForCausalLM"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5865dbb6-ee30-4593-9cb2-c4961c54f4df",
   "metadata": {},
   "source": [
    "The results below were extracted by experimenting around with the code [for this class](https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt_neo/modeling_gpt_neo.py), playing with the parameters until I could reliably reproduce parts of the model. I summarize a version of this below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a6f56-3912-4b8a-bc6b-7b1b8a9a4961",
   "metadata": {},
   "source": [
    "## Extracting the parameters from the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74953ce2-624f-4034-8a85-6fb1e8e8dfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoSelfAttention(\n",
       "  (attn_dropout): Dropout(p=0, inplace=False)\n",
       "  (resid_dropout): Dropout(p=0, inplace=False)\n",
       "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer zero self-attention - 'h' specifies the layers in a ModuleList\n",
    "att0 = model.transformer.h[0].attn.attention\n",
    "att0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e9b99e9-49f3-465d-809e-5598538b7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query projection\n",
    "Q = att0.q_proj.weight.data.numpy()\n",
    "\n",
    "# Key projection\n",
    "K = att0.k_proj.weight.data.numpy()\n",
    "\n",
    "# Value projection\n",
    "V = att0.v_proj.weight.data.numpy()\n",
    "\n",
    "# Output projection (with biases, others have no biases)\n",
    "O = att0.out_proj.weight.data.numpy()\n",
    "Ob = att0.out_proj.bias.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f704b322-801d-4cbb-aaf7-7e2151c9ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dict storing hyperparameters\n",
    "config = model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1033ff-1069-4f91-8f2d-c7f6d4644cbb",
   "metadata": {},
   "source": [
    "## Running self-attention as a reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9af167-d5b1-4315-92e1-8827e12fa93f",
   "metadata": {},
   "source": [
    "Making some dummy embedding vectors\n",
    "\n",
    "\n",
    "Generating \"fully random\" vectors often results in attention weights equal to the identity matrix, which isn't the best to test replication. Multiplying by the identity is a no-op, and we want to make sure that we apply the attention weights correctly.\n",
    "\n",
    "Instead, we'll generate a base vector and add some small noise to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75396389-a20c-4404-a735-f34680e51fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2349058)\n",
    "base_dv = np.random.rand(1, 768)\n",
    "\n",
    "# sequence length X hidden dimension\n",
    "dvs = np.empty((5, 768), dtype=np.float32)\n",
    "dvs[0, :] = base_dv\n",
    "dvs[1:, :] = np.random.randn(4, 768)*0.05 + base_dv\n",
    "\n",
    "# Making a tensor for PyTorch code\n",
    "# batch X sequence length X hidden dimension\n",
    "dvs_t = torch.tensor(dvs).view(1, 5, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33073d6c-8140-43e9-83d5-17b947c2cf9e",
   "metadata": {},
   "source": [
    "This is just running the code within the `att0.forward` method manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc771d8e-5d32-470b-8f44-b943b4abcf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# heads: 12, head dimension: 64\n"
     ]
    }
   ],
   "source": [
    "num_heads = config.num_heads\n",
    "head_dim = config.hidden_size // num_heads\n",
    "\n",
    "print(f\"# heads: {num_heads}, head dimension: {head_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b868f05-8189-4d65-afcd-5d9e6e3b7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = att0._split_heads(att0.q_proj(dvs_t), num_heads, head_dim)\n",
    "k = att0._split_heads(att0.k_proj(dvs_t), num_heads, head_dim)\n",
    "v = att0._split_heads(att0.v_proj(dvs_t), num_heads, head_dim)\n",
    "\n",
    "# ao = value-multiplied attention output per head\n",
    "# aw = attention weights\n",
    "ao, aw = att0._attn(q, k, v)\n",
    "\n",
    "ao_ = att0._merge_heads(ao, num_heads, head_dim)\n",
    "# fo = final output\n",
    "fo = att0.out_proj(ao_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b128309a-8c0a-4125-8610-28b6cee77812",
   "metadata": {},
   "source": [
    "Checking the attention weights. Again, if these turn out to be the identity matrix, these vectors aren't the best test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d83c17-2fdf-4991-8da2-830cdbaad031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.2767e-05, 9.9999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [8.8918e-13, 1.4486e-12, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [3.4189e-10, 3.6326e-09, 1.0000e+00, 3.0019e-06, 0.0000e+00],\n",
       "        [3.2485e-11, 2.9238e-11, 1.0000e+00, 2.6672e-09, 1.8745e-08]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting head 0\n",
    "aw[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c92c1cd-ad1a-4455-9005-3de5b5b253a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [7.9256e-06, 9.9999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [4.6404e-12, 3.7506e-07, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.3137e-11, 8.1386e-07, 1.0000e+00, 1.5599e-16, 0.0000e+00],\n",
       "        [1.4078e-11, 9.4648e-07, 1.0000e+00, 4.9371e-16, 1.6365e-12]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting head 1\n",
    "aw[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db418823-29fc-435a-83a1-80af765ff703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-23.1595,  -4.3884,   1.0211, -35.5319,  53.8781],\n",
       "         [-23.1733,  -9.9036,   2.5395, -32.8883,  52.2064],\n",
       "         [-23.7669,  -5.7476,   4.7038, -33.8980,  52.6261],\n",
       "         [-20.4753,  -7.8682,  -1.8134, -38.4741,  53.1547],\n",
       "         [-22.1756,  -2.8764,   0.0873, -33.7324,  54.9025]]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo[..., :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f80a651-d05b-48df-866a-eb6056b0c129",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reproducing self-attention using the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c39461-0bca-48e8-81c1-25ae8d994d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def headQK(Q, K, head_index):\n",
    "    assert head_index >= 0\n",
    "    assert head_index < num_heads\n",
    "    \n",
    "    i = head_index\n",
    "    Qh = Q[i*64:(i+1)*64, :]\n",
    "    Kh = K[i*64:(i+1)*64, :]\n",
    "        \n",
    "    return Qh.T @ Kh\n",
    "\n",
    "\n",
    "def headOV(O, V, head_index):\n",
    "    assert head_index >= 0\n",
    "    assert head_index < num_heads\n",
    "    \n",
    "    i = head_index\n",
    "    Oh = O[:, i*64:(i+1)*64]\n",
    "    Vh = V[i*64:(i+1)*64, :]\n",
    "    \n",
    "    return Oh @ Vh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52035491-8a4c-48da-82ee-e2d74d7f9775",
   "metadata": {},
   "source": [
    "#### Reproducing the attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05cd0b19-e5be-43d1-97fe-d0eba8f66ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The code calls the causal mask the \"bias\" for some reason.\n",
    "# It also extends to the maximum context size, but we don't need that\n",
    "# for our example of 5 vectors.\n",
    "causal_mask = att0.bias[0, 0, :5, :5].numpy()\n",
    "\n",
    "causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1e5e40d-4ad4-4748-a3fc-d39af72a807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_weights(inputs, Q, K, head_index):\n",
    "    raw = inputs @ headQK(Q, K, head_index) @ inputs.T\n",
    "    final = torch.nn.functional.softmax(\n",
    "        # raw weights with causal mask\n",
    "        torch.tensor(np.where(causal_mask == 1, raw, -1e9)),\n",
    "        dim=-1,\n",
    "    ).numpy()\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc862fd9-498a-461b-b0be-2c3856592c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.2767e-05, 9.9999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [8.8901e-13, 1.4484e-12, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [3.4183e-10, 3.6322e-09, 1.0000e+00, 3.0012e-06, 0.0000e+00],\n",
       "       [3.2482e-11, 2.9234e-11, 1.0000e+00, 2.6669e-09, 1.8745e-08]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights(dvs, Q, K, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85bff03d-7d4e-49cf-9e79-914c9b013e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [7.9251e-06, 9.9999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [4.6404e-12, 3.7506e-07, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.3138e-11, 8.1397e-07, 1.0000e+00, 1.5600e-16, 0.0000e+00],\n",
       "       [1.4078e-11, 9.4644e-07, 1.0000e+00, 4.9375e-16, 1.6364e-12]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights(dvs, Q, K, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c055326-ee13-4ab9-bd19-67e549e9b2c6",
   "metadata": {},
   "source": [
    "These match the `aw` outputs above. Moving on to the whole self-attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e63674f-b389-4656-b48c-379273ad4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfattention(inputs, Q, K, O, V, head_index):\n",
    "    aw = attention_weights(inputs, Q, K, head_index)\n",
    "    return aw @ inputs @ headOV(O, V, head_index).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb59014-114a-4610-bca8-42443542f496",
   "metadata": {},
   "source": [
    "Summing across heads and adding the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "604385eb-b715-470e-81f9-cdadac45b687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-23.1595,  -4.3884,   1.0211, -35.5319,  53.8781],\n",
       "       [-23.1733,  -9.9036,   2.5395, -32.8883,  52.2064],\n",
       "       [-23.7669,  -5.7476,   4.7038, -33.898 ,  52.6261],\n",
       "       [-20.4753,  -7.8682,  -1.8134, -38.4741,  53.1547],\n",
       "       [-22.1756,  -2.8764,   0.0873, -33.7324,  54.9025]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sum(selfattention(dvs, Q, K, O, V, i) for i in range(12)) + Ob\n",
    "result[..., :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c85daed-f016-421a-8365-f3b17fc8de2e",
   "metadata": {},
   "source": [
    "This matches the final output above :tada:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpt-neo)",
   "language": "python",
   "name": "gpt-neo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
